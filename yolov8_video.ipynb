{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection in Video Frames with YOLOv8m\n",
    "\n",
    "This example demonstrates the object detection model inference on the embedded Neural Processing Unit (NPU) in your AMD Ryzen AI enabled PC with either single image or the live webcam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.8)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 7)) (12.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 8)) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 10)) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 12)) (0.23.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 14)) (0.36.0)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 17)) (2.20.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 22)) (2.3.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 23)) (0.13.2)\n",
      "Requirement already satisfied: onnx>=1.12.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 28)) (1.18.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 35)) (9.8.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 36)) (7.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 37)) (7.1.3)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 38)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pycocotools>=2.0.6 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from -r requirements.txt (line 40)) (2.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 13)) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.33.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2025.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (1.8.19)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (8.7.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from ipykernel->-r requirements.txt (line 36)) (6.5.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from jedi>=0.18.1->ipython->-r requirements.txt (line 35)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 36)) (4.5.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 35)) (0.2.14)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r requirements.txt (line 35)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r requirements.txt (line 35)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r requirements.txt (line 35)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from sympy>=1.13.3->torch>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\stefan\\miniforge3\\envs\\ryzen-ai\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Before starting, be sure you've installed the requirements listed in the requirements.txt file:\n",
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model from Ryzen AI model zoo\n",
    "The yolov8m model from [Ryzen AI model zoo](https://huggingface.co/amd) will be applied in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stefan\\miniforge3\\envs\\ryzen-ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Stefan\\Documents\\RyzenAI-SW-1.4.0\\tutorial\\yolov8\\yolov8_python\\yolov8_utils.py:21: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources as pkg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Stefan\\\\Documents\\\\RyzenAI-SW-1.4.0\\\\tutorial\\\\yolov8\\\\yolov8_python\\\\yolov8m.onnx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook dependencies\n",
    "from huggingface_hub import hf_hub_download\n",
    "from yolov8_utils import get_directories\n",
    "\n",
    "current_dir = get_directories()\n",
    "\n",
    "# Download Yolov8 model from Ryzen AI model zoo. Registration is required before download.\n",
    "hf_hub_download(repo_id=\"amd/yolov8m\", filename=\"yolov8m.onnx\", local_dir=str(current_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pre and post processing functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    return img\n",
    "\n",
    "\n",
    "class DFL(nn.Module):\n",
    "    # Integral module of Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "    def __init__(self, c1=16):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n",
    "        x = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1 = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, a = x.shape  # batch, channels, anchors\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(\n",
    "            b, 4, a\n",
    "        )\n",
    "\n",
    "\n",
    "def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n",
    "    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n",
    "    lt, rb = torch.split(distance, 2, dim)\n",
    "    x1y1 = anchor_points - lt\n",
    "    x2y2 = anchor_points + rb\n",
    "    if xywh:\n",
    "        c_xy = (x1y1 + x2y2) / 2\n",
    "        wh = x2y2 - x1y1\n",
    "        return torch.cat((c_xy, wh), dim)  # xywh bbox\n",
    "    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n",
    "\n",
    "\n",
    "def post_process(x):\n",
    "    dfl = DFL(16)\n",
    "    anchors = torch.tensor(\n",
    "        np.load(\n",
    "            \"./anchors.npy\",\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "    )\n",
    "    strides = torch.tensor(\n",
    "        np.load(\n",
    "            \"./strides.npy\",\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "    )\n",
    "    box, cls = torch.cat([xi.view(x[0].shape[0], 144, -1) for xi in x], 2).split(\n",
    "        (16 * 4, 80), 1\n",
    "    )\n",
    "    dbox = dist2bbox(dfl(box), anchors.unsqueeze(0), xywh=True, dim=1) * strides\n",
    "    y = torch.cat((dbox, cls.sigmoid()), 1)\n",
    "    return y, x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Dataset\n",
    "This will download 555 MB so may take a while depending on the download bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone --progress https://github.com/JoyKarmoker/YOLOv8-Object-Detection-on-Video-with-OpenCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Video to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video motorbikes.mp4 has 686 frames\n"
     ]
    }
   ],
   "source": [
    "from yolov8_utils import *\n",
    "\n",
    "imgsz = [640, 640]\n",
    "video_name =  \"motorbikes.mp4\"\n",
    "video_path = f\"./YOLOv8-Object-Detection-on-Video-with-OpenCV/Videos/{video_name}\"\n",
    "\n",
    "# Load image\n",
    "dataset = LoadImages(\n",
    "    video_path, imgsz=imgsz, stride=32, auto=False, transforms=None, vid_stride=1\n",
    ")\n",
    "\n",
    "num_frames = 0\n",
    "for frame in dataset:\n",
    "    num_frames += 1\n",
    "\n",
    "print(f\"Video {video_name} has {num_frames} frames\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Target Hardware and set Environment\n",
    "\n",
    "read the PCI device ids, detect the type of the target hardware and set the environment accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APU Type: PHX/HPT\n",
      "Setting environment for PHX/HPT\n",
      "XLNX_VART_FIRMWARE= C:\\Program Files\\RyzenAI\\1.6.1\\voe-4.0-win_amd64\\xclbins\\phoenix\\Nx4.xclbin\n",
      "NUM_OF_DPU_RUNNERS= 1\n",
      "XLNX_TARGET_NAME= AMD_AIE2_Nx4_Overlay\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "command = r'pnputil /enum-devices /bus PCI /deviceids '\n",
    "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "# Check for supported Hardware IDs\n",
    "apu_type = ''\n",
    "if 'PCI\\\\VEN_1022&DEV_1502&REV_00' in stdout.decode(errors=\"ignore\"): apu_type = 'PHX/HPT'\n",
    "if 'PCI\\\\VEN_1022&DEV_17F0&REV_00' in stdout.decode(errors=\"ignore\"): apu_type = 'STX'\n",
    "if 'PCI\\\\VEN_1022&DEV_17F0&REV_10' in stdout.decode(errors=\"ignore\"): apu_type = 'STX'\n",
    "if 'PCI\\\\VEN_1022&DEV_17F0&REV_11' in stdout.decode(errors=\"ignore\"): apu_type = 'STX'\n",
    "\n",
    "print(f\"APU Type: {apu_type}\")\n",
    "\n",
    "# For Benchmarking\n",
    "#overlay = 'AMD_AIE2P_4x4_Overlay'\n",
    "overlay = 'AMD_AIE2P_Nx4_Overlay'\n",
    "\n",
    "install_dir = os.environ['RYZEN_AI_INSTALLATION_PATH']\n",
    "match apu_type:\n",
    "    case 'PHX/HPT':\n",
    "        print(\"Setting environment for PHX/HPT\")\n",
    "        #aie_array = '4x4'\n",
    "        aie_array = 'Nx4'\n",
    "        os.environ['XLNX_VART_FIRMWARE']= os.path.join(install_dir, 'voe-4.0-win_amd64', 'xclbins', 'phoenix', f'{aie_array}.xclbin')\n",
    "        os.environ['NUM_OF_DPU_RUNNERS']='1'\n",
    "        #os.environ['XLNX_TARGET_NAME']= f'AMD_AIE2_{aie_array}_Overlay'\n",
    "        os.environ['XLNX_TARGET_NAME']= f'AMD_AIE2_{aie_array}_Overlay'\n",
    "    case 'STX':\n",
    "        print(\"Setting environment for STX\")\n",
    "        aie_array = '4x4'\n",
    "        #aie_array = 'Nx4'\n",
    "        os.environ['XLNX_VART_FIRMWARE']= os.path.join(install_dir, 'voe-4.0-win_amd64', 'xclbins', 'strix', f'AMD_AIE2P_{aie_array}_Overlay.xclbin')\n",
    "        os.environ['NUM_OF_DPU_RUNNERS']='1'\n",
    "        os.environ['XLNX_TARGET_NAME']= f'AMD_AIE2P_{aie_array}_Overlay'\n",
    "        #os.environ['XLNX_TARGET_NAME']= f'AMD_AIE2P_{aie_array}_Overlay'\n",
    "    case _:\n",
    "        print(\"Unrecognized APU type. Exiting.\")\n",
    "        exit()\n",
    "print('XLNX_VART_FIRMWARE=', os.environ['XLNX_VART_FIRMWARE'])\n",
    "print('NUM_OF_DPU_RUNNERS=', os.environ['NUM_OF_DPU_RUNNERS'])\n",
    "print('XLNX_TARGET_NAME=', os.environ['XLNX_TARGET_NAME'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on Video Frames\n",
    "\n",
    "We will leverage the onnxruntime to do run inference on a sequence of video frames. The exeuction provider (EP) can be chosen to run inference on CPU, iGPU and NPU.\n",
    "The bounding boxes of the detected objects will then be drawn on the image and visualised as output video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the execution provider and create the inference session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for PHX/HPT\n",
      "onnxruntime.InferenceSession created\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "install_dir = os.environ['RYZEN_AI_INSTALLATION_PATH']\n",
    "model       = 'yolov8m.onnx'\n",
    "config_file = os.path.join(install_dir, 'voe-4.0-win_amd64', 'vaip_config.json')\n",
    "cache_dir = Path.cwd().resolve()\n",
    "cache_key   = 'modelcachekey_yolo'\n",
    "providers   = ['VitisAIExecutionProvider']\n",
    "\n",
    "if os.path.exists(cache_dir/cache_key) and os.path.isdir(cache_dir/cache_key):\n",
    "    # Remove the directory and its contents\n",
    "    shutil.rmtree(cache_dir/cache_key)\n",
    "    print(f\"{cache_dir/cache_key} has been removed.\")\n",
    "\n",
    "print(\"Setting environment for PHX/HPT\")\n",
    "xclbin_file = os.path.join(install_dir, 'voe-4.0-win_amd64', 'xclbins', 'phoenix', '4x4.xclbin')\n",
    "provider_options = [{\n",
    "        'cache_dir': cache_dir,\n",
    "        'cache_key': cache_key,\n",
    "        'target': 'X1',\n",
    "        'xclbin': xclbin_file\n",
    "    }]\n",
    "\n",
    "npu_session = onnxruntime.InferenceSession(\n",
    "    model,\n",
    "    providers = providers,\n",
    "    provider_options = provider_options\n",
    ")\n",
    "print(f\"onnxruntime.InferenceSession created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run object detection inference on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average inference time with EP: 29.47 ms\n",
      "Video processing time: 12.71 s\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "# Load labels of coco dataaset\n",
    "with open('coco.names', 'r') as f:\n",
    "        names = f.read()\n",
    "\n",
    "names = names.splitlines()\n",
    "\n",
    "inference_output_dir = \"inference_output\"\n",
    "\n",
    "if not os.path.exists(inference_output_dir):\n",
    "    os.mkdir(inference_output_dir)\n",
    "\n",
    "dataset = LoadImages(\n",
    "    video_path, imgsz=imgsz, stride=32, auto=False, transforms=None, vid_stride=3\n",
    ")\n",
    "max_det = 300\n",
    "\n",
    "print(f\"Running Inference on frames in video with model on ONNX EP\")\n",
    "num_frames = 0\n",
    "video_start_time = time.time()\n",
    "total_inference_time = 0\n",
    "for batch in dataset:\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "\n",
    "    im = preprocess(im)\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]\n",
    "\n",
    "    input_image = im.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    start = time.time()\n",
    "    outputs = npu_session.run(None, {npu_session.get_inputs()[0].name: input_image})\n",
    "    end = time.time()\n",
    "\n",
    "    inference_time = np.round((end - start) * 1000, 2)\n",
    "    total_inference_time += inference_time\n",
    "\n",
    "    # Postprocessing\n",
    "    outputs = [torch.tensor(item).permute(0, 3, 1, 2) for item in outputs]\n",
    "    preds = post_process(outputs)\n",
    "    preds = non_max_suppression(\n",
    "        preds, 0.25, 0.7, agnostic=False, max_det=max_det, classes=None\n",
    "    )\n",
    "    \n",
    "    output_path = f\"{inference_output_dir}/{video_name}_frame_{num_frames}.jpg\"\n",
    "    clear_output(wait=True) # clear the output cell\n",
    "    \n",
    "    if isinstance(names, list):\n",
    "        names = \"\\n\".join(names)\n",
    "\n",
    "    plot_images(\n",
    "        im,\n",
    "        *output_to_target(preds, max_det=max_det),\n",
    "        fname=output_path,\n",
    "        names=names,\n",
    "    )\n",
    "    num_frames += 1\n",
    "\n",
    "    num_det_objects = preds[0].size(0)\n",
    "    #print(f\"Detected {num_det_objects} Objects. Inference time: {inference_time} ms\")\n",
    "\n",
    "video_time = np.round((time.time() - video_start_time), 2)\n",
    "avg_inference_time = total_inference_time / num_frames\n",
    "print(f\"\\nAverage inference time with EP: {avg_inference_time:.2f} ms\")\n",
    "print(f\"Video processing time: {video_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Analyse model execution on NPU\n",
    "If AIA was set to true, data was generated for AI Analyzer and it will be launched in a webbrowser by the following cell. Documentation for the tool can be found here: https://ryzenai.docs.amd.com/en/latest/ai_analyzer.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AIA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mAIA\u001b[49m:\n\u001b[32m      2\u001b[39m     get_ipython().system(\u001b[33m'\u001b[39m\u001b[33maianalyzer ./ -p 8001\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'AIA' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#if AIA:\n",
    "#    !aianalyzer ./ -p 8001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryzen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
